{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRIJNANDA1979/DrivenDATA_competetion/blob/main/Version_1.2_CNN_for_DRIVEDATA_project_accuracy_74.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bold text** After Finishing Step 2 of preperation of Data....Now its time to run CNN on newly prepared data in Project 2023 folder under name\n",
        "\"TRAIN_DATA_for_CNN"
      ],
      "metadata": {
        "id": "gO4BfJvVKdGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCmUzIPJLHC6",
        "outputId": "ac805288-4f4f-4499-8829-b2996d518346"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu May 13 03:02:04 2021\n",
        "\n",
        "@author: BRIJB\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# import the needed packages\n",
        "import tensorflow as tf\n",
        "from keras import losses\n",
        "from keras import optimizers\n",
        "from keras import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import tensorflow.keras as keras\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "import os\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oGyaQhr3u8Tc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define and move to dataset directory\n",
        "datasetdir = \"/content/drive/MyDrive/Project 2023/DRIVEN_DATA competetion/TRAIN_DATA_for_CNN\"\n",
        "import os\n",
        "os.chdir(datasetdir)"
      ],
      "metadata": {
        "id": "4Zy8c0FbK_A5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shortcut to the ImageDataGenerator class\n",
        "ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator\n",
        "gen = ImageDataGenerator()\n",
        "iterator = gen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size=(64,64),\n",
        "    #classes=('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake')\n",
        "    classes = ('antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent')\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeY_UE0jvDf9",
        "outputId": "440f4265-fcdb-4bca-d811-c6e749ee9b54"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16488 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = iterator.next()\n",
        "print(len(batch))\n",
        "print(type(batch[0]))\n",
        "print(batch[0].shape)\n",
        "print(batch[0].dtype)\n",
        "#the first element is an array of 32 images with 64X64 pixels, and 3 color channels, encoded as floats in the range 0 to 255\n",
        "#The second element contains the 32 corresponding labels."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfewz4kqvp-s",
        "outputId": "08fdda52-35fb-4ab0-e90a-83e74da27275"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 64, 64, 3)\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = iterator.next()\n",
        "print(len(batch))\n",
        "print(type(batch[1]))\n",
        "print(batch[1].shape)\n",
        "print(batch[1].dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaPqr20bv-M_",
        "outputId": "248bc650-0193-4f88-c346-3216da800b4e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 8)\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgdatagen = ImageDataGenerator(\n",
        "    rescale = 1/255.,\n",
        "    validation_split = 0.2,\n",
        ")\n",
        "\n",
        "batch_size = 32\n",
        "height, width = (64,64)\n",
        "train_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width),\n",
        "    #classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    classes = ('antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_dataset = imgdatagen.flow_from_directory(\n",
        "    os.getcwd(),\n",
        "    target_size = (height, width),\n",
        "    #classes = ('Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential','SeaLake'),\n",
        "    classes = ('antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent'),\n",
        "    batch_size = batch_size,\n",
        "    subset = 'validation'\n",
        ")\n",
        "#In this case out of 5000 images: Training: 4000 Validation: 20% of 4000 i.e. 1000\n",
        "model = keras.models.Sequential()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPMpBo_MwKz-",
        "outputId": "182bd24f-c6dc-4318-bed2-d98d7ab33b1c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13195 images belonging to 8 classes.\n",
            "Found 3293 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "initializers = {\n",
        "\n",
        "}\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Conv2D(\n",
        "        24, 5, input_shape=(64,64,3),\n",
        "        activation='relu',\n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.MaxPooling2D(2) )\n",
        "model.add(\n",
        "    keras.layers.Conv2D(\n",
        "        48, 5, activation='relu',\n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.MaxPooling2D(2) )\n",
        "model.add(\n",
        "    keras.layers.Conv2D(\n",
        "        96, 5, activation='relu',\n",
        "    )\n",
        ")\n",
        "model.add( keras.layers.Flatten() )\n",
        "model.add( keras.layers.Dropout(0.4) )\n",
        "\n",
        "model.add( keras.layers.Dense(\n",
        "    8, activation='softmax',\n",
        "    )\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8rpuGkKwu_b",
        "outputId": "53566d4d-6b7e-47f5-892a-58df374e83b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 60, 60, 24)        1824      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 30, 30, 24)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 48)        28848     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 48)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 9, 9, 96)          115296    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 7776)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 7776)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 62216     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 208184 (813.22 KB)\n",
            "Trainable params: 208184 (813.22 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.Adamax(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFJa65dKwxsn",
        "outputId": "2df5c2dd-de30-4742-85c7-ae138c2d0fb5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adamax.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    train_dataset,\n",
        "    validation_data = val_dataset,\n",
        "    workers=10,\n",
        "    epochs=20,\n",
        ")\n",
        "\n",
        "#result of this model is not impressive, but can be imroved\n",
        "#443/443 [==============================] - 363s 802ms/step - loss: 0.3290 - acc: 0.3072 - val_loss: 0.2291 - val_acc: 0.5466"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdeBADn8w74E",
        "outputId": "833f158f-9de5-4259-887e-a449b8995168"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-4b65afdb626c>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "413/413 [==============================] - 790s 2s/step - loss: 0.3485 - acc: 0.2722 - val_loss: 0.3170 - val_acc: 0.3568\n",
            "Epoch 2/20\n",
            "413/413 [==============================] - 174s 420ms/step - loss: 0.3019 - acc: 0.4087 - val_loss: 0.2874 - val_acc: 0.4531\n",
            "Epoch 3/20\n",
            "413/413 [==============================] - 181s 433ms/step - loss: 0.2775 - acc: 0.4733 - val_loss: 0.2767 - val_acc: 0.4904\n",
            "Epoch 4/20\n",
            "413/413 [==============================] - 179s 432ms/step - loss: 0.2577 - acc: 0.5253 - val_loss: 0.2523 - val_acc: 0.5430\n",
            "Epoch 5/20\n",
            "413/413 [==============================] - 184s 442ms/step - loss: 0.2421 - acc: 0.5627 - val_loss: 0.2384 - val_acc: 0.5664\n",
            "Epoch 6/20\n",
            "413/413 [==============================] - 182s 437ms/step - loss: 0.2268 - acc: 0.6039 - val_loss: 0.2193 - val_acc: 0.6404\n",
            "Epoch 7/20\n",
            "413/413 [==============================] - 179s 431ms/step - loss: 0.2127 - acc: 0.6363 - val_loss: 0.2136 - val_acc: 0.6395\n",
            "Epoch 8/20\n",
            "413/413 [==============================] - 179s 432ms/step - loss: 0.2019 - acc: 0.6667 - val_loss: 0.2068 - val_acc: 0.6493\n",
            "Epoch 9/20\n",
            "413/413 [==============================] - 179s 432ms/step - loss: 0.1920 - acc: 0.6859 - val_loss: 0.1963 - val_acc: 0.6790\n",
            "Epoch 10/20\n",
            "413/413 [==============================] - 182s 439ms/step - loss: 0.1821 - acc: 0.7067 - val_loss: 0.1885 - val_acc: 0.6742\n",
            "Epoch 11/20\n",
            "413/413 [==============================] - 173s 417ms/step - loss: 0.1751 - acc: 0.7235 - val_loss: 0.1823 - val_acc: 0.7021\n",
            "Epoch 12/20\n",
            "413/413 [==============================] - 173s 417ms/step - loss: 0.1683 - acc: 0.7372 - val_loss: 0.1777 - val_acc: 0.7148\n",
            "Epoch 13/20\n",
            "413/413 [==============================] - 178s 428ms/step - loss: 0.1608 - acc: 0.7504 - val_loss: 0.1739 - val_acc: 0.7179\n",
            "Epoch 14/20\n",
            "413/413 [==============================] - 177s 426ms/step - loss: 0.1557 - acc: 0.7580 - val_loss: 0.1701 - val_acc: 0.7297\n",
            "Epoch 15/20\n",
            "413/413 [==============================] - 175s 422ms/step - loss: 0.1507 - acc: 0.7685 - val_loss: 0.1638 - val_acc: 0.7379\n",
            "Epoch 16/20\n",
            "413/413 [==============================] - 173s 416ms/step - loss: 0.1450 - acc: 0.7823 - val_loss: 0.1608 - val_acc: 0.7480\n",
            "Epoch 17/20\n",
            "413/413 [==============================] - ETA: 0s - loss: 0.1399 - acc: 0.7889"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result 1 with Epochs =10   Epoch 10/10\n",
        "\n",
        "#86/86 [==============================] - 45s 518ms/step - loss: 0.1856 - acc: 0.7538 - val_loss: 0.1883 - val_acc: 0.7555"
      ],
      "metadata": {
        "id": "dM14_ZA0vMh5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}